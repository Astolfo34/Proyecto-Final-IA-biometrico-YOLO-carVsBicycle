{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66781568",
   "metadata": {},
   "source": [
    "# Notebook Colab: Detección y Clasificación Bicicleta vs Auto (YOLOv8)\n",
    "\n",
    "**Autor:** Generado automáticamente.\n",
    "\n",
    "Este cuaderno implementa un flujo completo para entrenar, evaluar e inferir un modelo YOLOv8 que detecta bicicletas y autos usando datasets en formato YOLO v8 dentro de `Z_ProyectoYolo/datasets`.\n",
    "\n",
    "---\n",
    "## Índice de Secciones\n",
    "0. Setup\n",
    "1. Definición y justificación\n",
    "2. Verificación de dataset\n",
    "3. Visualización de datos y comprobaciones\n",
    "4. Preparación de `data.yaml`\n",
    "5. Selección del modelo y justificación\n",
    "6. Entrenamiento\n",
    "7. Visualización de logs y métricas\n",
    "8. Evaluación cuantitativa\n",
    "9. Inferencia (solo imágenes)\n",
    "10. Empaquetado y entrega\n",
    "11. Informe final (markdown y opcional PDF)\n",
    "12. Checklist final\n",
    "\n",
    "Ejecute cada sección en orden. Todo el contenido está en español y las rutas son relativas para reproducibilidad en Google Colab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87177e4",
   "metadata": {},
   "source": [
    "## 0. Setup\n",
    "\n",
    "Instala dependencias, detecta Colab y prepara variables y carpetas del proyecto. Las rutas son relativas a `PROJECT_ROOT = 'Z_ProyectoYolo'`.\n",
    "\n",
    "- Dependencias: `ultralytics`, `opencv-python-headless`, `matplotlib`, `pandas`, `tqdm`, `scikit-learn`, `seaborn`, `pyyaml`.\n",
    "- Opción de montar Google Drive en Colab (desactivado por defecto; active `DO_MOUNT_DRIVE=True` si desea guardar en Drive).\n",
    "- Fijación de semillas para reproducibilidad.\n",
    "- Selección automática de dispositivo.\n",
    "- Creación de carpetas de salida si no existen.\n",
    "- Muestra versiones de `ultralytics` y `torch`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a89cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalación de dependencias y configuración inicial\n",
    "# Nota: En Colab, esta celda instalará/actualizará las dependencias necesarias.\n",
    "\n",
    "import os, sys, json, random, shutil, time, glob\n",
    "from pathlib import Path\n",
    "\n",
    "# Detectar si estamos en Google Colab\n",
    "try:\n",
    "    import google.colab  # type: ignore\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "\n",
    "# (Opcional) Montar Drive en Colab\n",
    "DO_MOUNT_DRIVE = False  # Cambie a True si desea montar su Google Drive\n",
    "if IN_COLAB and DO_MOUNT_DRIVE:\n",
    "    from google.colab import drive  # type: ignore\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# Instalar dependencias clave\n",
    "if IN_COLAB:\n",
    "    # En Colab use pip mágico para salida limpia\n",
    "    %pip -q install ultralytics opencv-python-headless matplotlib pandas tqdm scikit-learn seaborn pyyaml\n",
    "else:\n",
    "    # En entornos locales también podemos instalar si faltan\n",
    "    import subprocess\n",
    "    def _pip_install(pkgs):\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', *pkgs])\n",
    "        except Exception as e:\n",
    "            print('Aviso: no se pudo instalar', pkgs, e)\n",
    "    _pip_install(['ultralytics','opencv-python-headless','matplotlib','pandas','tqdm','scikit-learn','seaborn','pyyaml'])\n",
    "\n",
    "import yaml\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Fijar semillas para reproducibilidad\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "try:\n",
    "    import torch\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Seleccionar dispositivo\n",
    "try:\n",
    "    import torch\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "except Exception:\n",
    "    DEVICE = 'cpu'\n",
    "\n",
    "# Definir raíces del proyecto (evitar rutas absolutas fijas; preferir variables)\n",
    "PROJECT_ROOT = 'Z_ProyectoYolo'\n",
    "# Si estamos en Colab y el proyecto existe en la ruta de trabajo actual, usarla.\n",
    "# Si montó Drive y la carpeta existe allí, puede definir manualmente PROJECT_ROOT a esa ubicación.\n",
    "if IN_COLAB:\n",
    "    # Preferir carpeta en el cwd; si no existe pero existe en Drive, usarla.\n",
    "    if not Path(PROJECT_ROOT).exists() and Path('/content/drive/MyDrive/Z_ProyectoYolo').exists():\n",
    "        PROJECT_ROOT = '/content/drive/MyDrive/Z_ProyectoYolo'\n",
    "\n",
    "DATASET_ROOT = os.path.join(PROJECT_ROOT, 'datasets')\n",
    "\n",
    "# Directorios de salida\n",
    "RUNS_DIR = os.path.join(PROJECT_ROOT, 'runs')\n",
    "EVAL_DIR = os.path.join(PROJECT_ROOT, 'evaluation')\n",
    "EVAL_METRICS_DIR = os.path.join(EVAL_DIR, 'metrics')\n",
    "EVAL_FIG_DIR = os.path.join(EVAL_DIR, 'figures')\n",
    "INFER_DIR = os.path.join(PROJECT_ROOT, 'inference')\n",
    "INFER_RESULTS_DIR = os.path.join(INFER_DIR, 'results_images')\n",
    "INFER_NEW_IMG_DIR = os.path.join(INFER_DIR, 'images_new')\n",
    "ENTREGA_DIR = os.path.join(PROJECT_ROOT, 'entrega_final')\n",
    "ENTREGA_MODEL_DIR = os.path.join(ENTREGA_DIR, 'modelo')\n",
    "DOCS_DIR = os.path.join(PROJECT_ROOT, 'docs')\n",
    "\n",
    "# Crear carpetas requeridas\n",
    "for d in [RUNS_DIR, EVAL_METRICS_DIR, EVAL_FIG_DIR, INFER_RESULTS_DIR, INFER_NEW_IMG_DIR, ENTREGA_MODEL_DIR, DOCS_DIR]:\n",
    "    Path(d).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Mostrar versiones\n",
    "from importlib.metadata import version, PackageNotFoundError\n",
    "\n",
    "def _ver(pkg):\n",
    "    try:\n",
    "        return version(pkg)\n",
    "    except PackageNotFoundError:\n",
    "        return 'no-instalado'\n",
    "\n",
    "ultra_ver = _ver('ultralytics')\n",
    "torch_ver = _ver('torch')\n",
    "print(f\"IN_COLAB={IN_COLAB} | DEVICE={DEVICE}\")\n",
    "print(f\"ultralytics=={ultra_ver} | torch=={torch_ver}\")\n",
    "\n",
    "# Guardar requirements.txt con versiones actuales (para reproducibilidad en Colab)\n",
    "# Nota: esto sobrescribe el requirements.txt con versiones concretas del entorno actual\n",
    "req_path = os.path.join(PROJECT_ROOT, 'requirements.txt')\n",
    "try:\n",
    "    import pkgutil\n",
    "    import subprocess\n",
    "    freeze = subprocess.check_output([sys.executable, '-m', 'pip', 'freeze'], text=True)\n",
    "    with open(req_path, 'w') as f:\n",
    "        f.write(freeze)\n",
    "    print(f\"Guardado {req_path} con versiones instaladas.\")\n",
    "except Exception as e:\n",
    "    print('Aviso: no se pudo escribir requirements.txt:', e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cfe4b3",
   "metadata": {},
   "source": [
    "## 1. Definición y justificación\n",
    "\n",
    "**Objetivo:** Entrenar y evaluar un detector YOLOv8 capaz de detectar y clasificar objetos de las clases bicicleta y auto en imágenes.\n",
    "\n",
    "**Justificación (usabilidad):**\n",
    "- Conteo de tráfico y análisis de movilidad urbana.\n",
    "- Seguridad vial y monitoreo de zonas con alta circulación.\n",
    "- Gestión de estacionamientos y control de acceso en recintos.\n",
    "- Apoyo a ciudades inteligentes para planificación de infraestructura.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ea681a",
   "metadata": {},
   "source": [
    "## 2. Verificación de dataset\n",
    "\n",
    "Validación de estructura, conteo de imágenes por split/clase y detección de inconsistencias. Se generan resúmenes en `evaluation/metrics/` y notas en `docs/labeling_notes.md`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0185c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificación de la estructura del dataset y conteos\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "required_dirs = [\n",
    "    os.path.join(DATASET_ROOT, 'images', 'train'),\n",
    "    os.path.join(DATASET_ROOT, 'images', 'val'),\n",
    "    os.path.join(DATASET_ROOT, 'labels', 'train'),\n",
    "    os.path.join(DATASET_ROOT, 'labels', 'val'),\n",
    "]\n",
    "\n",
    "missing_reqs = [d for d in required_dirs if not Path(d).exists()]\n",
    "if missing_reqs:\n",
    "    print(\"ADVERTENCIA: Faltan directorios requeridos:\")\n",
    "    for d in missing_reqs:\n",
    "        print(\" -\", d)\n",
    "else:\n",
    "    print(\"Estructura mínima encontrada.\")\n",
    "\n",
    "IMG_EXT = {'.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff', '.webp'}\n",
    "\n",
    "split_stats = {}\n",
    "label_issues = { 'missing_label_for_image': [], 'empty_label_file': [], 'malformed_lines': [] }\n",
    "class_counts = { 'train': Counter(), 'val': Counter() }\n",
    "image_counts = { 'train': 0, 'val': 0 }\n",
    "instance_counts = { 'train': 0, 'val': 0 }\n",
    "\n",
    "for split in ['train','val']:\n",
    "    img_dir = os.path.join(DATASET_ROOT, 'images', split)\n",
    "    lab_dir = os.path.join(DATASET_ROOT, 'labels', split)\n",
    "    imgs = []\n",
    "    if Path(img_dir).exists():\n",
    "        for p in Path(img_dir).glob('*'):\n",
    "            if p.suffix.lower() in IMG_EXT:\n",
    "                imgs.append(p)\n",
    "    image_counts[split] = len(imgs)\n",
    "\n",
    "    # Verificar que cada imagen tenga su .txt correspondiente\n",
    "    for img_path in imgs:\n",
    "        label_path = Path(lab_dir) / (img_path.stem + '.txt')\n",
    "        if not label_path.exists():\n",
    "            label_issues['missing_label_for_image'].append(str(img_path))\n",
    "            continue\n",
    "        # Leer archivo de etiquetas\n",
    "        try:\n",
    "            with open(label_path, 'r') as f:\n",
    "                lines = [ln.strip() for ln in f.readlines() if ln.strip()]\n",
    "        except Exception as e:\n",
    "            label_issues['malformed_lines'].append(f\"{label_path} :: error apertura {e}\")\n",
    "            continue\n",
    "        if len(lines) == 0:\n",
    "            label_issues['empty_label_file'].append(str(label_path))\n",
    "        for ln in lines:\n",
    "            parts = ln.split()\n",
    "            if len(parts) != 5:\n",
    "                label_issues['malformed_lines'].append(f\"{label_path} :: '{ln}'\")\n",
    "                continue\n",
    "            try:\n",
    "                cls_id = int(float(parts[0]))\n",
    "                # YOLOv8 usa: class cx cy w h (normalizados)\n",
    "                _ = [float(x) for x in parts[1:]]\n",
    "                if cls_id not in [0,1]:\n",
    "                    label_issues['malformed_lines'].append(f\"{label_path} :: clase inválida {cls_id}\")\n",
    "                    continue\n",
    "                class_counts[split][cls_id] += 1\n",
    "                instance_counts[split] += 1\n",
    "            except Exception:\n",
    "                label_issues['malformed_lines'].append(f\"{label_path} :: '{ln}' (parse)\")\n",
    "\n",
    "# Resumen por split\n",
    "summary_rows = []\n",
    "for split in ['train','val']:\n",
    "    row = {\n",
    "        'split': split,\n",
    "        'images': image_counts[split],\n",
    "        'instances_total': instance_counts[split],\n",
    "        'instances_bicicleta(cls0)': class_counts[split][0],\n",
    "        'instances_auto(cls1)': class_counts[split][1],\n",
    "    }\n",
    "    summary_rows.append(row)\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df\n",
    "\n",
    "# Guardar resumen\n",
    "summary_csv = os.path.join(EVAL_METRICS_DIR, 'dataset_summary.csv')\n",
    "summary_json = os.path.join(EVAL_METRICS_DIR, 'dataset_summary.json')\n",
    "summary_df.to_csv(summary_csv, index=False)\n",
    "with open(summary_json, 'w') as f:\n",
    "    json.dump({\n",
    "        'images': image_counts,\n",
    "        'instances': instance_counts,\n",
    "        'class_counts': {k: dict(v) for k,v in class_counts.items()},\n",
    "        'issues_counts': {k: len(v) for k,v in label_issues.items()}\n",
    "    }, f, indent=2)\n",
    "print('Guardado resumen en:', summary_csv, 'y', summary_json)\n",
    "\n",
    "# Guardar notas de etiquetado\n",
    "label_notes = os.path.join(DOCS_DIR, 'labeling_notes.md')\n",
    "with open(label_notes, 'a') as f:\n",
    "    f.write('\\n\\n## Verificación automática\\n')\n",
    "    f.write(f\"\\nFecha: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    if label_issues['missing_label_for_image']:\n",
    "        f.write('\\n### Imágenes sin archivo de etiqueta (.txt)\\n')\n",
    "        for p in label_issues['missing_label_for_image']:\n",
    "            f.write(f\"- {p}\\n\")\n",
    "    if label_issues['empty_label_file']:\n",
    "        f.write('\\n### Archivos de etiqueta vacíos\\n')\n",
    "        for p in label_issues['empty_label_file']:\n",
    "            f.write(f\"- {p}\\n\")\n",
    "    if label_issues['malformed_lines']:\n",
    "        f.write('\\n### Líneas mal formateadas\\n')\n",
    "        for desc in label_issues['malformed_lines']:\n",
    "            f.write(f\"- {desc}\\n\")\n",
    "\n",
    "# Advertencia por desbalance o escasez (<50 instancias por clase)\n",
    "for split in ['train','val']:\n",
    "    for cls_id, cls_name in [(0,'bicicleta'),(1,'auto')]:\n",
    "        if class_counts[split][cls_id] < 50:\n",
    "            print(f\"ADVERTENCIA: Clase '{cls_name}' en split '{split}' tiene menos de 50 instancias ({class_counts[split][cls_id]}). Considere aumentar los datos.\")\n",
    "\n",
    "# Mensaje de balance\n",
    "def _imbalance_msg(cc):\n",
    "    total = cc[0] + cc[1]\n",
    "    if total == 0:\n",
    "        return 'sin instancias'\n",
    "    ratio = (cc[0] / total) if total > 0 else 0\n",
    "    return f\"bicicleta={cc[0]} ({ratio:.1%}), auto={cc[1]} ({1-ratio:.1%})\"\n",
    "\n",
    "print('Distribución train:', _imbalance_msg(class_counts['train']))\n",
    "print('Distribución val  :', _imbalance_msg(class_counts['val']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8728628",
   "metadata": {},
   "source": [
    "## 3. Visualización de datos y comprobaciones\n",
    "\n",
    "Se muestran 8–12 ejemplos aleatorios del split de entrenamiento con bounding boxes dibujados a partir de los archivos de etiqueta YOLO (`class cx cy w h`). La figura se guarda en `evaluation/figures/sample_grid.png`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72de415d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización aleatoria de ejemplos etiquetados del split train\n",
    "import math\n",
    "\n",
    "train_img_dir = os.path.join(DATASET_ROOT, 'images', 'train')\n",
    "train_lab_dir = os.path.join(DATASET_ROOT, 'labels', 'train')\n",
    "all_train_imgs = [p for p in Path(train_img_dir).glob('*') if p.suffix.lower() in IMG_EXT]\n",
    "\n",
    "n_show = 12 if len(all_train_imgs) >= 12 else max(1, len(all_train_imgs))\n",
    "sel = random.sample(all_train_imgs, n_show) if len(all_train_imgs) >= n_show else all_train_imgs\n",
    "\n",
    "class_names = {0: 'bicicleta', 1: 'auto'}\n",
    "fig_cols = 4\n",
    "fig_rows = math.ceil(len(sel)/fig_cols)\n",
    "plt.figure(figsize=(16, 4*fig_rows))\n",
    "\n",
    "missing_label_imgs = []\n",
    "\n",
    "for i, img_path in enumerate(sel, 1):\n",
    "    lab_path = Path(train_lab_dir) / (img_path.stem + '.txt')\n",
    "    img = cv2.imread(str(img_path))\n",
    "    if img is None:\n",
    "        continue\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    H, W = img.shape[:2]\n",
    "    if not lab_path.exists():\n",
    "        missing_label_imgs.append(str(img_path))\n",
    "        boxes = []\n",
    "    else:\n",
    "        with open(lab_path, 'r') as f:\n",
    "            lines = [ln.strip() for ln in f.readlines() if ln.strip()]\n",
    "        boxes = []\n",
    "        for ln in lines:\n",
    "            parts = ln.split()\n",
    "            if len(parts) != 5:\n",
    "                continue\n",
    "            try:\n",
    "                cls_id = int(float(parts[0]))\n",
    "                cx, cy, w, h = map(float, parts[1:])\n",
    "                # Convertir normalizados a pixeles\n",
    "                x1 = int((cx - w/2) * W)\n",
    "                y1 = int((cy - h/2) * H)\n",
    "                x2 = int((cx + w/2) * W)\n",
    "                y2 = int((cy + h/2) * H)\n",
    "                boxes.append((x1,y1,x2,y2,cls_id))\n",
    "            except Exception:\n",
    "                continue\n",
    "    # Dibujar\n",
    "    img_draw = img.copy()\n",
    "    for (x1,y1,x2,y2,cls_id) in boxes:\n",
    "        color = (0,255,0) if cls_id == 1 else (255,0,0)\n",
    "        cv2.rectangle(img_draw, (x1,y1), (x2,y2), color, 2)\n",
    "        label = class_names.get(cls_id, f\"cls{cls_id}\")\n",
    "        cv2.putText(img_draw, label, (x1, max(0,y1-5)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "    plt.subplot(fig_rows, fig_cols, i)\n",
    "    plt.imshow(img_draw)\n",
    "    plt.axis('off')\n",
    "    plt.title(img_path.name)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig_path = os.path.join(EVAL_FIG_DIR, 'sample_grid.png')\n",
    "plt.savefig(fig_path, dpi=150)\n",
    "plt.show()\n",
    "print('Guardada figura de ejemplos en:', fig_path)\n",
    "\n",
    "# Registrar imágenes sin label en labeling_notes.md\n",
    "if missing_label_imgs:\n",
    "    with open(os.path.join(DOCS_DIR, 'labeling_notes.md'), 'a') as f:\n",
    "        f.write('\\n### Imágenes sin label detectadas en visualización (train)\\n')\n",
    "        for p in missing_label_imgs:\n",
    "            f.write(f\"- {p}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f9bf8c",
   "metadata": {},
   "source": [
    "## 4. Preparación de `data.yaml`\n",
    "\n",
    "Se crea y valida el archivo de configuración con rutas relativas y nombres de clases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ca36d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear/validar data.yaml con rutas relativas y clases\n",
    "DATA_YAML_PATH = os.path.join(PROJECT_ROOT, 'data.yaml')\n",
    "\n",
    "data_cfg = {\n",
    "    'train': 'Z_ProyectoYolo/datasets/images/train',\n",
    "    'val':   'Z_ProyectoYolo/datasets/images/val',\n",
    "    'nc': 2,\n",
    "    'names': ['bicicleta','auto']\n",
    "}\n",
    "\n",
    "with open(DATA_YAML_PATH, 'w') as f:\n",
    "    yaml.safe_dump(data_cfg, f, sort_keys=False, allow_unicode=True)\n",
    "\n",
    "print('Escrito:', DATA_YAML_PATH)\n",
    "print('Contenido:')\n",
    "print(yaml.safe_dump(data_cfg, sort_keys=False, allow_unicode=True))\n",
    "\n",
    "# Validar rutas\n",
    "assert Path(os.path.join(PROJECT_ROOT, 'datasets', 'images', 'train')).exists(), 'No existe images/train'\n",
    "assert Path(os.path.join(PROJECT_ROOT, 'datasets', 'images', 'val')).exists(), 'No existe images/val'\n",
    "assert Path(os.path.join(PROJECT_ROOT, 'datasets', 'labels', 'train')).exists(), 'No existe labels/train'\n",
    "assert Path(os.path.join(PROJECT_ROOT, 'datasets', 'labels', 'val')).exists(), 'No existe labels/val'\n",
    "print('Validación básica de rutas OK.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecd70a3",
   "metadata": {},
   "source": [
    "## 5. Selección del modelo y justificación\n",
    "\n",
    "Se utiliza `yolov8n.pt` por su ligereza y buena compatibilidad con Colab gratuito. Alternativa: `yolov8s.pt` para mayor precisión si la GPU lo permite. Hiperparámetros iniciales:\n",
    "- `IMGSZ = 640`\n",
    "- `EPOCHS = 50`\n",
    "- `BATCH = 16` (si OOM: intentar 8, luego 4)\n",
    "- Augmentaciones por defecto de YOLOv8: mosaic, volteo horizontal, HSV, escala.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e218f87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de hiperparámetros y selección de modelo\n",
    "MODEL_BACKBONE = 'yolov8n.pt'  # alternativa: 'yolov8s.pt'\n",
    "IMGSZ = 640\n",
    "EPOCHS = 50\n",
    "BATCH = 16\n",
    "print(f\"Modelo: {MODEL_BACKBONE} | IMGSZ={IMGSZ} | EPOCHS={EPOCHS} | BATCH={BATCH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640d27e1",
   "metadata": {},
   "source": [
    "## 6. Entrenamiento\n",
    "\n",
    "Comando reproducible (CLI):\n",
    "\n",
    "```\n",
    "!yolo detect train model={MODEL_BACKBONE} data=Z_ProyectoYolo/data.yaml imgsz=640 epochs=50 batch=16 project=runs name=exp_bici_auto\n",
    "```\n",
    "\n",
    "A continuación se ejecuta el entrenamiento con la API de Python (manejo de OOM reduciendo batch 16→8→4). Se normaliza la ubicación de `best.pt` a `Z_ProyectoYolo/runs/exp_bici_auto/weights/best.pt` si Ultralytics usa subcarpeta `detect/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57df25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento con reintento ante OOM y normalización de rutas de salida\n",
    "from ultralytics import YOLO\n",
    "\n",
    "os.makedirs(RUNS_DIR, exist_ok=True)\n",
    "\n",
    "# Asegurar cwd a raíz del proyecto (para que runs/ quede dentro de Z_ProyectoYolo)\n",
    "os.chdir(Path(PROJECT_ROOT))\n",
    "print('CWD for training:', os.getcwd())\n",
    "\n",
    "cli_cmd = f\"yolo detect train model={MODEL_BACKBONE} data=Z_ProyectoYolo/data.yaml imgsz={IMGSZ} epochs={EPOCHS} batch={BATCH} project=runs name=exp_bici_auto\"\n",
    "print('Comando reproducible CLI:\\n', cli_cmd)\n",
    "\n",
    "batches = [BATCH, 8, 4] if BATCH != 8 else [8, 4]\n",
    "train_success = False\n",
    "train_save_dir = None\n",
    "for b in batches:\n",
    "    try:\n",
    "        print(f\"\\nIntentando entrenamiento con batch={b} ...\")\n",
    "        model = YOLO(MODEL_BACKBONE)\n",
    "        results = model.train(\n",
    "            data='Z_ProyectoYolo/data.yaml',\n",
    "            imgsz=IMGSZ,\n",
    "            epochs=EPOCHS,\n",
    "            batch=b,\n",
    "            project='runs',\n",
    "            name='exp_bici_auto',\n",
    "            verbose=True,\n",
    "        )\n",
    "        # Intentar obtener el directorio de guardado\n",
    "        try:\n",
    "            train_save_dir = str(model.trainer.save_dir)\n",
    "        except Exception:\n",
    "            train_save_dir = None\n",
    "        train_success = True\n",
    "        break\n",
    "    except RuntimeError as e:\n",
    "        if 'out of memory' in str(e).lower():\n",
    "            print('OOM detectado. Probando con batch menor...')\n",
    "            continue\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "if not train_success:\n",
    "    raise RuntimeError('Entrenamiento falló en todos los tamaños de batch.')\n",
    "\n",
    "# Normalizar ruta: asegurar Z_ProyectoYolo/runs/exp_bici_auto/weights/best.pt\n",
    "norm_run_dir = os.path.join('Z_ProyectoYolo', 'runs', 'exp_bici_auto')\n",
    "Path(norm_run_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Buscar best.pt en subcarpetas de runs\n",
    "best_candidate = None\n",
    "for p in Path('Z_ProyectoYolo/runs').rglob('best.pt'):\n",
    "    if 'exp_bici_auto' in str(p):\n",
    "        best_candidate = p\n",
    "        break\n",
    "\n",
    "if best_candidate is None:\n",
    "    # También revisar si Ultralytics guardó en runs/exp_bici_auto directamente (con cwd en PROJECT_ROOT)\n",
    "    for p in Path('runs').rglob('best.pt'):\n",
    "        if 'exp_bici_auto' in str(p):\n",
    "            best_candidate = p\n",
    "            break\n",
    "\n",
    "if best_candidate is None:\n",
    "    print('ADVERTENCIA: No se encontró best.pt. Verifique el entrenamiento.')\n",
    "else:\n",
    "    dest_dir = os.path.join('Z_ProyectoYolo', 'runs', 'exp_bici_auto', 'weights')\n",
    "    Path(dest_dir).mkdir(parents=True, exist_ok=True)\n",
    "    dest_path = os.path.join(dest_dir, 'best.pt')\n",
    "    shutil.copy2(str(best_candidate), dest_path)\n",
    "    print('best.pt normalizado a:', dest_path)\n",
    "\n",
    "# Volver cwd por seguridad\n",
    "os.chdir('..')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34e81d6",
   "metadata": {},
   "source": [
    "## 7. Visualización de logs y métricas\n",
    "\n",
    "Se extraen métricas de entrenamiento (losses, precisión, recall, mAP) y se generan gráficos guardados en `evaluation/figures/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cba33bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar logs de entrenamiento y graficar métricas\n",
    "import pandas as pd\n",
    "\n",
    "# Intentar localizar el directorio del experimento\n",
    "candidates = [\n",
    "    os.path.join(PROJECT_ROOT, 'runs', 'exp_bici_auto'),\n",
    "    os.path.join(PROJECT_ROOT, 'runs', 'detect', 'exp_bici_auto'),\n",
    "]\n",
    "run_dir = None\n",
    "for c in candidates:\n",
    "    if Path(c).exists():\n",
    "        run_dir = c\n",
    "        break\n",
    "\n",
    "if run_dir is None:\n",
    "    # Buscar por results.csv en runs\n",
    "    for p in Path(os.path.join(PROJECT_ROOT, 'runs')).rglob('results.csv'):\n",
    "        if 'exp_bici_auto' in str(p):\n",
    "            run_dir = str(p.parent)\n",
    "            break\n",
    "\n",
    "if run_dir is None:\n",
    "    raise FileNotFoundError('No se encontró el directorio de corrida con results.csv')\n",
    "\n",
    "results_csv = os.path.join(run_dir, 'results.csv')\n",
    "print('results.csv:', results_csv)\n",
    "results = pd.read_csv(results_csv)\n",
    "\n",
    "# Graficar pérdidas por epoch\n",
    "loss_cols = [c for c in results.columns if 'loss' in c.lower()]\n",
    "plt.figure(figsize=(10,6))\n",
    "for col in loss_cols:\n",
    "    plt.plot(results.index, results[col], label=col)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Pérdidas por epoch')\n",
    "plt.legend()\n",
    "loss_fig = os.path.join(EVAL_FIG_DIR, 'losses.png')\n",
    "plt.savefig(loss_fig, dpi=150)\n",
    "plt.show()\n",
    "print('Guardado gráfico de pérdidas en:', loss_fig)\n",
    "\n",
    "# Graficar Precision/Recall y mAP\n",
    "metric_cols = {}\n",
    "for key in ['precision', 'recall', 'mAP50', 'mAP50-95']:\n",
    "    # Buscar columnas que contengan las claves típicas de Ultralytics\n",
    "    matches = [c for c in results.columns if key.lower() in c.lower()]\n",
    "    if matches:\n",
    "        metric_cols[key] = matches[0]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "for key, col in metric_cols.items():\n",
    "    plt.plot(results.index, results[col], label=key)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('valor')\n",
    "plt.title('Precision / Recall / mAP')\n",
    "plt.legend()\n",
    "pr_fig = os.path.join(EVAL_FIG_DIR, 'pr_map.png')\n",
    "plt.savefig(pr_fig, dpi=150)\n",
    "plt.show()\n",
    "print('Guardado gráfico PR/mAP en:', pr_fig)\n",
    "\n",
    "# Consolidar métricas finales\n",
    "final_metrics = {}\n",
    "for key, col in metric_cols.items():\n",
    "    final_metrics[key] = float(results[col].iloc[-1])\n",
    "\n",
    "# Guardar en metrics.json (merge con dataset_summary)\n",
    "metrics_json = os.path.join(EVAL_METRICS_DIR, 'metrics.json')\n",
    "base = {}\n",
    "if Path(metrics_json).exists():\n",
    "    try:\n",
    "        base = json.load(open(metrics_json, 'r'))\n",
    "    except Exception:\n",
    "        base = {}\n",
    "base.update({'training': {\n",
    "    'run_dir': run_dir,\n",
    "    'final_metrics': final_metrics,\n",
    "}})\n",
    "with open(metrics_json, 'w') as f:\n",
    "    json.dump(base, f, indent=2)\n",
    "print('Métricas consolidadas en:', metrics_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd8d080",
   "metadata": {},
   "source": [
    "## 8. Evaluación cuantitativa\n",
    "\n",
    "Se ejecuta validación con el mejor modelo y se construye la matriz de confusión, consolidando métricas (Precision, Recall, mAP@0.5, mAP@0.5:0.95, IoU promedio). Fórmula del IoU:\n",
    "\n",
    "$$IoU = \\frac{|A \\cap B|}{|A \\cup B|}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5dad0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validación y matriz de confusión\n",
    "from ultralytics import YOLO\n",
    "\n",
    "best_path = os.path.join(PROJECT_ROOT, 'runs', 'exp_bici_auto', 'weights', 'best.pt')\n",
    "if not Path(best_path).exists():\n",
    "    # Buscar fallback\n",
    "    for p in Path(os.path.join(PROJECT_ROOT, 'runs')).rglob('best.pt'):\n",
    "        if 'exp_bici_auto' in str(p):\n",
    "            best_path = str(p)\n",
    "            break\n",
    "print('Usando modelo para evaluación:', best_path)\n",
    "\n",
    "model = YOLO(best_path)\n",
    "val_res = model.val(data=os.path.join(PROJECT_ROOT, 'data.yaml'), imgsz=IMGSZ)\n",
    "\n",
    "# Extraer métricas\n",
    "# Ultralytics produce un dict-like accesible a través de val_res.results_dict (en versiones recientes)\n",
    "metrics_out = {}\n",
    "try:\n",
    "    metrics_out = dict(val_res.results_dict)\n",
    "except Exception:\n",
    "    # Construir manualmente si no está disponible\n",
    "    try:\n",
    "        metrics_out = {\n",
    "            'precision': float(val_res.box.maps[0]) if hasattr(val_res, 'box') and hasattr(val_res.box, 'maps') else None\n",
    "        }\n",
    "    except Exception:\n",
    "        metrics_out = {}\n",
    "\n",
    "# Intentar recuperar PR/mAP de archivos\n",
    "res_csv = None\n",
    "for p in Path(os.path.join(PROJECT_ROOT, 'runs')).rglob('results.csv'):\n",
    "    if 'exp_bici_auto' in str(p):\n",
    "        res_csv = p\n",
    "        break\n",
    "if res_csv is not None:\n",
    "    df = pd.read_csv(res_csv)\n",
    "    def _pick(colname):\n",
    "        cand = [c for c in df.columns if colname.lower() in c.lower()]\n",
    "        return float(df[cand[0]].iloc[-1]) if cand else None\n",
    "    metrics_out.update({\n",
    "        'precision': metrics_out.get('precision') or _pick('precision'),\n",
    "        'recall': _pick('recall'),\n",
    "        'mAP50': _pick('map50'),\n",
    "        'mAP50-95': _pick('map50-95'),\n",
    "    })\n",
    "\n",
    "# IoU promedio (si disponible)\n",
    "try:\n",
    "    if hasattr(val_res, 'box') and hasattr(val_res.box, 'iou'):  # versiones futuras\n",
    "        metrics_out['IoU'] = float(np.mean(val_res.box.iou))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Guardar matriz de confusión si existe\n",
    "cm_png = None\n",
    "for p in Path(os.path.join(PROJECT_ROOT, 'runs')).rglob('confusion_matrix.png'):\n",
    "    if 'exp_bici_auto' in str(p):\n",
    "        cm_png = str(p)\n",
    "        break\n",
    "if cm_png:\n",
    "    # Copiar a evaluation/figures\n",
    "    dest_cm = os.path.join(EVAL_FIG_DIR, 'confusion_matrix.png')\n",
    "    shutil.copy2(cm_png, dest_cm)\n",
    "    print('Matriz de confusión guardada en:', dest_cm)\n",
    "\n",
    "# Guardar métricas\n",
    "metrics_json = os.path.join(EVAL_METRICS_DIR, 'metrics.json')\n",
    "base = {}\n",
    "if Path(metrics_json).exists():\n",
    "    try:\n",
    "        base = json.load(open(metrics_json, 'r'))\n",
    "    except Exception:\n",
    "        base = {}\n",
    "base['validation'] = metrics_out\n",
    "with open(metrics_json, 'w') as f:\n",
    "    json.dump(base, f, indent=2)\n",
    "print('Métricas de evaluación guardadas en:', metrics_json)\n",
    "\n",
    "# Sugerencias automáticas\n",
    "sugs = []\n",
    "if metrics_out.get('mAP50', 0) and metrics_out['mAP50'] < 0.6:\n",
    "    sugs.append('Recolectar más datos y balancear clases (especialmente la minoritaria).')\n",
    "    sugs.append('Aumentar épocas o probar backbone más grande (yolov8s).')\n",
    "if metrics_out.get('precision', 1) < 0.6:\n",
    "    sugs.append('Revisar anotaciones (falsos positivos pueden indicar cajas imprecisas).')\n",
    "if metrics_out.get('recall', 1) < 0.6:\n",
    "    sugs.append('Mejorar cobertura de datos y diversidad; ajustar umbral de confianza en inferencia.')\n",
    "print('Sugerencias:', '\\n- ' + '\\n- '.join(sugs) if sugs else 'Modelo con desempeño razonable.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99591db",
   "metadata": {},
   "source": [
    "## 9. Inferencia (solo imágenes)\n",
    "\n",
    "Se ejecuta inferencia sobre `datasets/images/val` y, si existen, sobre `inference/images_new/`. Las imágenes con predicciones se consolidan en `inference/results_images/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d61f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inferencia con best.pt sobre val y (opcional) imágenes nuevas\n",
    "from ultralytics import YOLO\n",
    "\n",
    "best_path = os.path.join(PROJECT_ROOT, 'runs', 'exp_bici_auto', 'weights', 'best.pt')\n",
    "assert Path(best_path).exists(), f\"No se encontró el modelo: {best_path}\"\n",
    "\n",
    "model = YOLO(best_path)\n",
    "\n",
    "# Función para predecir y consolidar imágenes de salida\n",
    "def run_predict_and_collect(source_dir, target_dir, imgsz=IMGSZ, conf=0.25):\n",
    "    if not Path(source_dir).exists():\n",
    "        print('No existe fuente de imágenes:', source_dir)\n",
    "        return []\n",
    "    print('Inferencia en:', source_dir)\n",
    "    res = model.predict(source=source_dir, imgsz=imgsz, conf=conf, save=True, project=os.path.join(PROJECT_ROOT, 'inference'), name='tmp_pred', exist_ok=True)\n",
    "    # Buscar imágenes resultantes y copiarlas a target_dir\n",
    "    Path(target_dir).mkdir(parents=True, exist_ok=True)\n",
    "    saved_imgs = []\n",
    "    # La salida suele estar en PROJECT_ROOT/inference/tmp_pred/predictX\n",
    "    out_base = os.path.join(PROJECT_ROOT, 'inference', 'tmp_pred')\n",
    "    candidate = None\n",
    "    # Preferir último directorio predict*\n",
    "    preds = sorted([p for p in Path(out_base).glob('predict*') if p.is_dir()], key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "    if preds:\n",
    "        candidate = preds[0]\n",
    "    if candidate:\n",
    "        for imgp in candidate.glob('*.jpg'):\n",
    "            dest = Path(target_dir) / imgp.name\n",
    "            shutil.copy2(str(imgp), str(dest))\n",
    "            saved_imgs.append(str(dest))\n",
    "        for imgp in candidate.glob('*.png'):\n",
    "            dest = Path(target_dir) / imgp.name\n",
    "            shutil.copy2(str(imgp), str(dest))\n",
    "            saved_imgs.append(str(dest))\n",
    "    print(f\"{len(saved_imgs)} imágenes guardadas en {target_dir}\")\n",
    "    return saved_imgs\n",
    "\n",
    "# Inferencia en val\n",
    "val_img_dir = os.path.join(PROJECT_ROOT, 'datasets', 'images', 'val')\n",
    "val_preds = run_predict_and_collect(val_img_dir, INFER_RESULTS_DIR)\n",
    "\n",
    "# Inferencia en nuevas imágenes (si las hay)\n",
    "new_preds = run_predict_and_collect(INFER_NEW_IMG_DIR, INFER_RESULTS_DIR)\n",
    "\n",
    "# Mostrar algunos aciertos/fallos\n",
    "def show_examples(paths, title, max_n=6):\n",
    "    if not paths:\n",
    "        print('Sin ejemplos para', title)\n",
    "        return\n",
    "    n = min(max_n, len(paths))\n",
    "    sel = random.sample(paths, n)\n",
    "    cols = 3\n",
    "    rows = math.ceil(n/cols)\n",
    "    plt.figure(figsize=(12, 4*rows))\n",
    "    for i,p in enumerate(sel,1):\n",
    "        img = cv2.imread(p)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) if img is not None else None\n",
    "        plt.subplot(rows, cols, i)\n",
    "        if img is None:\n",
    "            plt.text(0.5,0.5,'No se pudo cargar', ha='center', va='center')\n",
    "        else:\n",
    "            plt.imshow(img); plt.axis('off')\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    out_name = 'qualitative_examples.png' if 'aciertos' in title.lower() else 'failure_cases.png'\n",
    "    out_path = os.path.join(EVAL_FIG_DIR, out_name)\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.show()\n",
    "    print('Guardado en:', out_path)\n",
    "\n",
    "show_examples(val_preds[:], 'Ejemplos de inferencia en val (aciertos y fallos mixtos)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5ae94c",
   "metadata": {},
   "source": [
    "## 10. Empaquetado y entrega\n",
    "\n",
    "Se empaquetan artefactos a `Z_ProyectoYolo/entrega_final/entrega_final.zip` y se imprimen los comandos para descargar en Colab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020c9a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empaquetar artefactos finales\n",
    "\n",
    "# Guardar el propio cuaderno dentro del proyecto con nombre canónico\n",
    "try:\n",
    "    from IPython.display import display, Javascript\n",
    "    # Nota: En Colab, guardar el notebook requiere acción del usuario\n",
    "    print('Asegúrese de guardar este notebook como Z_ProyectoYolo/notebook.ipynb')\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Copiar artefactos a entrega_final/\n",
    "NB_PATH = os.path.join(PROJECT_ROOT, 'notebook.ipynb')\n",
    "REQ_PATH = os.path.join(PROJECT_ROOT, 'requirements.txt')\n",
    "DATA_YAML_PATH = os.path.join(PROJECT_ROOT, 'data.yaml')\n",
    "BEST_PT = os.path.join(PROJECT_ROOT, 'runs', 'exp_bici_auto', 'weights', 'best.pt')\n",
    "\n",
    "os.makedirs(ENTREGA_MODEL_DIR, exist_ok=True)\n",
    "if Path(BEST_PT).exists():\n",
    "    shutil.copy2(BEST_PT, os.path.join(ENTREGA_MODEL_DIR, 'best.pt'))\n",
    "\n",
    "# Copiar carpetas seleccionadas\n",
    "def copy_tree(src, dst):\n",
    "    if not Path(src).exists():\n",
    "        return\n",
    "    Path(dst).mkdir(parents=True, exist_ok=True)\n",
    "    for root, dirs, files in os.walk(src):\n",
    "        rel = os.path.relpath(root, src)\n",
    "        out_dir = os.path.join(dst, rel)\n",
    "        Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "        for fn in files:\n",
    "            shutil.copy2(os.path.join(root, fn), os.path.join(out_dir, fn))\n",
    "\n",
    "copy_tree(os.path.join(PROJECT_ROOT, 'evaluation'), os.path.join(ENTREGA_DIR, 'evaluation'))\n",
    "copy_tree(os.path.join(PROJECT_ROOT, 'inference'), os.path.join(ENTREGA_DIR, 'inference'))\n",
    "copy_tree(os.path.join(PROJECT_ROOT, 'docs'), os.path.join(ENTREGA_DIR, 'docs'))\n",
    "\n",
    "# Copiar archivos sueltos\n",
    "for p in [NB_PATH, REQ_PATH, DATA_YAML_PATH, os.path.join(PROJECT_ROOT, 'informe.md')]:\n",
    "    if Path(p).exists():\n",
    "        shutil.copy2(p, ENTREGA_DIR)\n",
    "\n",
    "# Crear ZIP\n",
    "zip_base = os.path.join(PROJECT_ROOT, 'entrega_final', 'entrega_final')\n",
    "zip_path = shutil.make_archive(zip_base, 'zip', ENTREGA_DIR)\n",
    "print('ZIP creado en:', zip_path)\n",
    "\n",
    "# Comando para descargar en Colab\n",
    "print('\\nPara descargar en Colab ejecute:')\n",
    "print(\"from google.colab import files; files.download('Z_ProyectoYolo/entrega_final/entrega_final.zip')\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3e45ca",
   "metadata": {},
   "source": [
    "## 11. Informe final (3–5 páginas en `informe.md`)\n",
    "\n",
    "Se auto-genera un informe en Markdown con las secciones pedidas. Opcionalmente, se puede convertir a PDF si `pandoc` está disponible en el entorno.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff67890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generación automática de informe en markdown\n",
    "\n",
    "def _read_metrics(metrics_json):\n",
    "    if Path(metrics_json).exists():\n",
    "        try:\n",
    "            return json.load(open(metrics_json,'r'))\n",
    "        except Exception:\n",
    "            return {}\n",
    "    return {}\n",
    "\n",
    "def _list_images(dir_path, exts={'.png','.jpg','.jpeg'}):\n",
    "    if not Path(dir_path).exists():\n",
    "        return []\n",
    "    return [str(p) for p in Path(dir_path).glob('*') if p.suffix.lower() in exts]\n",
    "\n",
    "metrics_json = os.path.join(EVAL_METRICS_DIR, 'metrics.json')\n",
    "metrics_all = _read_metrics(metrics_json)\n",
    "\n",
    "# Selección de imágenes ejemplo\n",
    "qual_imgs = _list_images(EVAL_FIG_DIR)\n",
    "inf_imgs = _list_images(INFER_RESULTS_DIR)\n",
    "\n",
    "md_lines = []\n",
    "md_lines.append('# Informe del Proyecto: Detección Bicicleta vs Auto (YOLOv8)')\n",
    "md_lines.append('')\n",
    "md_lines.append('## 1. Problema y justificación (usabilidad)')\n",
    "md_lines.append('- Detección y clasificación de bicicletas y autos en imágenes fijas.')\n",
    "md_lines.append('- Casos de uso: conteo de tráfico, seguridad vial, estacionamientos, ciudades inteligentes.')\n",
    "md_lines.append('')\n",
    "md_lines.append('## 2. Dataset y estructura')\n",
    "md_lines.append(f\"- Raíz del dataset: `{DATASET_ROOT}`\")\n",
    "md_lines.append('- Estructura: images/{train,val} y labels/{train,val} en formato YOLO.')\n",
    "md_lines.append('- Verificación automática en `evaluation/metrics/dataset_summary.*`.')\n",
    "md_lines.append('')\n",
    "md_lines.append('## 3. Configuración de entrenamiento')\n",
    "md_lines.append(f\"- Modelo: `{MODEL_BACKBONE}` | IMGSZ={IMGSZ} | EPOCHS={EPOCHS}\")\n",
    "md_lines.append('- Aumentos: mosaic, flip horizontal, HSV, scale (por defecto YOLOv8).')\n",
    "md_lines.append('')\n",
    "md_lines.append('## 4. Resultados y métricas')\n",
    "train_metrics = metrics_all.get('training', {}).get('final_metrics', {})\n",
    "val_metrics = metrics_all.get('validation', {})\n",
    "md_lines.append('### Métricas de entrenamiento (última época)')\n",
    "md_lines.append('' if train_metrics else '*No disponible*')\n",
    "for k,v in train_metrics.items():\n",
    "    md_lines.append(f\"- {k}: {v:.4f}\")\n",
    "md_lines.append('')\n",
    "md_lines.append('### Métricas de validación')\n",
    "if val_metrics:\n",
    "    for k,v in val_metrics.items():\n",
    "        try:\n",
    "            md_lines.append(f\"- {k}: {float(v):.4f}\")\n",
    "        except Exception:\n",
    "            md_lines.append(f\"- {k}: {v}\")\n",
    "else:\n",
    "    md_lines.append('*No disponible*')\n",
    "md_lines.append('')\n",
    "md_lines.append('Se adjuntan figuras en `evaluation/figures/` y ejemplos cualitativos en `inference/results_images/`.')\n",
    "md_lines.append('')\n",
    "md_lines.append('## 5. Conclusiones y recomendaciones')\n",
    "md_lines.append('- Aumentar datos para la clase minoritaria si hay desbalance.')\n",
    "md_lines.append('- Mejorar calidad de anotación en casos dudosos.')\n",
    "md_lines.append('- Probar `yolov8s.pt` y ajustar épocas si la GPU lo permite.')\n",
    "\n",
    "# Escribir informe\n",
    "informe_path = os.path.join(PROJECT_ROOT, 'informe.md')\n",
    "with open(informe_path, 'w') as f:\n",
    "    f.write('\\n'.join(md_lines))\n",
    "print('Informe generado en:', informe_path)\n",
    "\n",
    "# Conversión opcional a PDF si pandoc está disponible\n",
    "try:\n",
    "    import subprocess\n",
    "    pdf_out = os.path.join(ENTREGA_DIR, 'informe.pdf')\n",
    "    subprocess.run(['pandoc', informe_path, '-o', pdf_out], check=False)\n",
    "    if Path(pdf_out).exists():\n",
    "        print('Informe PDF guardado en:', pdf_out)\n",
    "except Exception:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dfd48c",
   "metadata": {},
   "source": [
    "## 12. Checklist final (imprimible)\n",
    "\n",
    "Se verifica la existencia de los principales artefactos y rutas requeridas; se imprime una lista con ✅/❌.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dde45c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checklist final de artefactos\n",
    "checks = [\n",
    "    ('Z_ProyectoYolo/datasets/images/train', os.path.join(PROJECT_ROOT, 'datasets', 'images', 'train')),\n",
    "    ('Z_ProyectoYolo/datasets/images/val', os.path.join(PROJECT_ROOT, 'datasets', 'images', 'val')),\n",
    "    ('Z_ProyectoYolo/datasets/labels/train', os.path.join(PROJECT_ROOT, 'datasets', 'labels', 'train')),\n",
    "    ('Z_ProyectoYolo/datasets/labels/val', os.path.join(PROJECT_ROOT, 'datasets', 'labels', 'val')),\n",
    "    ('Z_ProyectoYolo/data.yaml', os.path.join(PROJECT_ROOT, 'data.yaml')),\n",
    "    ('Z_ProyectoYolo/runs/exp_bici_auto/weights/best.pt', os.path.join(PROJECT_ROOT, 'runs', 'exp_bici_auto', 'weights', 'best.pt')),\n",
    "    ('Z_ProyectoYolo/evaluation/metrics.json', os.path.join(PROJECT_ROOT, 'evaluation', 'metrics', 'metrics.json')),\n",
    "    ('Z_ProyectoYolo/evaluation/figures/', os.path.join(PROJECT_ROOT, 'evaluation', 'figures')),\n",
    "    ('Z_ProyectoYolo/inference/results_images/', os.path.join(PROJECT_ROOT, 'inference', 'results_images')),\n",
    "    ('Z_ProyectoYolo/docs/labeling_notes.md', os.path.join(PROJECT_ROOT, 'docs', 'labeling_notes.md')),\n",
    "    ('Z_ProyectoYolo/informe.md', os.path.join(PROJECT_ROOT, 'informe.md')),\n",
    "    ('Z_ProyectoYolo/entrega_final/entrega_final.zip', os.path.join(PROJECT_ROOT, 'entrega_final', 'entrega_final.zip')),\n",
    "]\n",
    "\n",
    "for label, path in checks:\n",
    "    exists = Path(path).exists()\n",
    "    mark = '✅' if exists else '❌'\n",
    "    print(f\"{mark} {label}\")\n",
    "\n",
    "print('\\nSi está en Colab y desea descargar el ZIP, ejecute:')\n",
    "print(\"from google.colab import files; files.download('Z_ProyectoYolo/entrega_final/entrega_final.zip')\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
